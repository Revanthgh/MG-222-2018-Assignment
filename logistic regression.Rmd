---
title: "Logistic regression"
author: "Revanth"
date: "1 April 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


#For ROC curve and AUROC
library(pROC)

#For train-test split
library(caTools)

#For k fold cross validation
library(caret)

#For stepAIC()
library(MASS)

##Remove non-important Variables (based on IV)
# Removing DHVAL DOUTCC DOUTL SINC NKID DOUTHP PHON DEP
publicc$DHVAL <- NULL
publicc$DOUTCC <- NULL
publicc$DOUTL <- NULL
publicc$SINC <- NULL
publicc$NKID <- NULL
publicc$DOUTHP <- NULL
publicc$PHON <- NULL
publicc$DEP <- NULL

View(publicc)
head(publicc)

# k-Fold Cross Validation

# Splitting the dataset into the Training set and Test set

set.seed(123)
split = sample.split(publicc$BAD, SplitRatio = 0.75)
publicc_train = subset(publicc, split == TRUE)
publicc_test = subset(publicc, split == FALSE)

##Training set has 75% values - Test set has 25% values

# Fitting LRM to the Training set
# Full Training set model and Prediction on Test Model
logistic_model = glm(formula = BAD ~ .*.,family = binomial,data = publicc_train)

log.aic <- stepAIC(logistic_model)
summary(log.aic)

# Important Variables BAD ~ DAINC + RES + DMORT + DAINC:DMORT + DAINC:AGE + DMORT:AGE

full_pred = predict(log.aic, type = 'response', newdata = publicc_test[-6])
plot.roc(publicc_test$BAD,full_pred,print.auc = TRUE)

#AUC - 59%


# Applying k-Fold Cross Validation


folds = createFolds(publicc_train$BAD, k = 10)

par(mfrow=c(4,4))


cross_validate = lapply(folds, function(x) {
  
  training_fold = publicc_train[-x, ]
  
  test_fold = publicc_train[x, ]
  
  logistic_model = glm(formula = BAD ~ DAINC + RES + DMORT + DAINC:DMORT + DAINC:AGE + DMORT:AGE,family = binomial,data = training_fold)
  
  ##Removing BAD from test data
  prob_pred = predict(logistic_model, type = 'response', newdata = test_fold[-6])
  
  plot.roc(test_fold$BAD,prob_pred,print.auc = TRUE)

  y_pred = ifelse(prob_pred < 0.5, 0, 1)
  
  conf_matrix = table(test_fold[, 6], y_pred)
  
  #accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1])
  
  #return(accuracy)
  return(conf_matrix)
})


comb_conf_matrix <- cross_validate


accuracy = 0
TotSens = 0
TotSpec = 0
for(folds in comb_conf_matrix){
  accuracy = accuracy + (folds[1]+folds[4])/(folds[1]+folds[2]+folds[3]+folds[4])*100
  TotSens = TotSens + folds[4]/(folds[2]+folds[4])*100
  TotSpec = TotSpec + folds[1]/(folds[3]+folds[1])*100
}

cat("Mean Accuracy :",accuracy/10,"\n Mean Sensitivity :", TotSens/10, "\nMean Specificity :", TotSpec/10)
cat("False Positive Rate :", 100 - TotSpec/10, "\nFalse Negative Rate :", 100 - TotSens/10)


